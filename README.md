# ğŸš€ Projeto de RegressÃ£o: PrevisÃ£o de PreÃ§os de ImÃ³veis ğŸ 

Este repositÃ³rio documenta minha jornada de aprendizado ao implementar o projeto ponta-a-ponta do CapÃ­tulo 2 do livro **"MÃ£os Ã  Obra: Aprendizado de MÃ¡quina com Scikit-Learn, Keras & TensorFlow"** (2Âª EdiÃ§Ã£o) de AurÃ©lien GÃ©ron.

O objetivo Ã© construir um modelo de regressÃ£o capaz de prever o valor mediano de imÃ³veis em distritos da CalifÃ³rnia, utilizando dados do censo de 1990.

---

## ğŸ¯ Objetivo Principal

O foco deste projeto nÃ£o Ã© apenas criar um modelo, mas sim praticar e solidificar o **processo completo de um projeto de Machine Learning** no mundo real.

Isso inclui desde a obtenÃ§Ã£o dos dados atÃ© a avaliaÃ§Ã£o final do sistema.

## ğŸ“ˆ O Pipeline de ML

Seguindo a metodologia do livro, o projeto Ã© dividido nas seguintes etapas:

1.  **ğŸ“¥ AquisiÃ§Ã£o dos Dados:**
    * CriaÃ§Ã£o de scripts para baixar e carregar o dataset (`housing.csv`).

2.  **ğŸ”­ AnÃ¡lise ExploratÃ³ria (EDA):**
    * Investigar as *features* (atributos) dos dados.
    * Criar visualizaÃ§Ãµes grÃ¡ficas (histogramas, *scatter plots*) para encontrar padrÃµes e correlaÃ§Ãµes.
    * Analisar a correlaÃ§Ã£o entre os atributos e o valor mediano (`median_house_value`).

3.  **ğŸ§¹ PreparaÃ§Ã£o e PrÃ©-processamento:**
    * Limpeza de dados: Tratar valores ausentes (ex: `total_bedrooms`).
    * Engenharia de *features*: Criar novos atributos relevantes (ex: `rooms_per_household`).
    * ConstruÃ§Ã£o de *Pipelines* do Scikit-Learn para automatizar a transformaÃ§Ã£o de dados (tratamento de texto, normalizaÃ§Ã£o, etc.).

4.  **ğŸ¤– Treinamento e SeleÃ§Ã£o de Modelos:**
    * Treinamento de mÃºltiplos modelos de regressÃ£o (RegressÃ£o Linear, Ãrvore de DecisÃ£o, Random Forest, etc.).
    * AvaliaÃ§Ã£o inicial dos modelos usando ValidaÃ§Ã£o Cruzada (*Cross-Validation*).

5.  **âš™ï¸ OtimizaÃ§Ã£o e AvaliaÃ§Ã£o Fina:**
    * Ajuste fino (*fine-tuning*) dos hiperparÃ¢metros dos melhores modelos usando `GridSearchCV`.
    * AvaliaÃ§Ã£o final do sistema no conjunto de teste para estimar o desempenho em dados nunca vistos.

## ğŸ› ï¸ Tecnologias e Bibliotecas Utilizadas

* **Python 3.x**
* **Pandas:** Para manipulaÃ§Ã£o e anÃ¡lise eficiente dos dados.
* **Scikit-Learn (sklearn):** A biblioteca central para o pipeline de ML, prÃ©-processamento, modelagem e avaliaÃ§Ã£o.
* **NumPy:** Para operaÃ§Ãµes numÃ©ricas.
* **Matplotlib & Seaborn:** Para a visualizaÃ§Ã£o de dados e *insights*.
* **Jupyter Notebook:** (Se vocÃª estiver usando) Para desenvolvimento iterativo e documentaÃ§Ã£o.

## ğŸ“– Fonte

Este projeto Ã© um exercÃ­cio de estudo baseado no CapÃ­tulo 2 do livro "Hands-On Machine Learning" e utiliza o [dataset clÃ¡ssico da CalifÃ³rnia](https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/housing/housing.tgz) disponibilizado pelo autor.
